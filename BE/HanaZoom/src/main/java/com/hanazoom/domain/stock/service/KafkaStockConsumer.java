package com.hanazoom.domain.stock.service;

import com.fasterxml.jackson.databind.JsonNode;
import com.fasterxml.jackson.databind.ObjectMapper;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.boot.autoconfigure.condition.ConditionalOnProperty;
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.messaging.handler.annotation.Header;
import org.springframework.messaging.handler.annotation.Payload;

import java.util.Map;
import org.springframework.stereotype.Service;

import javax.annotation.PostConstruct;

import java.time.LocalDateTime;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.atomic.AtomicLong;

@Slf4j
@Service
@RequiredArgsConstructor
@ConditionalOnProperty(value = "kafka.enabled", havingValue = "true", matchIfMissing = false)
public class KafkaStockConsumer {

    @PostConstruct
    public void init() {
        log.info("ğŸ¯ Kafka Consumer ì´ˆê¸°í™” ì‹œì‘ - WebSocketê³¼ ì™„ì „íˆ ë¶„ë¦¬ë¨");
        // KafkaëŠ” WebSocket ì´ˆê¸°í™”ì™€ ë¬´ê´€í•˜ê²Œ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ë™ì‘
        new Thread(() -> {
            try {
                // Kafka ì—°ê²° ì‹œë„ (WebSocketì— ì˜í–¥ ì—†ìŒ)
                Thread.sleep(2000); // WebSocket ì´ˆê¸°í™” ì™„ë£Œ ëŒ€ê¸°
                log.info("âœ… Kafka Consumer ì´ˆê¸°í™” ì™„ë£Œ - WebSocketê³¼ ë…ë¦½ì  ë™ì‘");
            } catch (Exception e) {
                log.warn("âš ï¸ Kafka ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ (WebSocketì—ëŠ” ì˜í–¥ ì—†ìŒ): {}", e.getMessage());
            }
        }).start();
    }

    private final ObjectMapper objectMapper;
    private final KafkaStockService kafkaStockService;

    // ì‹¤ì‹œê°„ ë°ì´í„° ì €ì¥ì†Œ (ë©”ëª¨ë¦¬ ìºì‹œ)
    private final Map<String, Map<String, Object>> realTimeStockCache = new ConcurrentHashMap<>();

    // ì„±ëŠ¥ ë©”íŠ¸ë¦­
    private final AtomicLong totalMessagesProcessed = new AtomicLong(0);
    private final AtomicLong totalProcessingTime = new AtomicLong(0);
    private final AtomicInteger activeConnections = new AtomicInteger(0);

    // Topics
    private static final String STOCK_REALTIME_TOPIC = "stock-realtime-data";
    private static final String PERFORMANCE_METRICS_TOPIC = "performance-metrics";

    /**
     * ì‹¤ì‹œê°„ ì£¼ì‹ ë°ì´í„° ìˆ˜ì‹ 
     */
    @KafkaListener(topics = STOCK_REALTIME_TOPIC, groupId = "wts-consumer-group")
    public void consumeRealTimeStockData(
            @Payload String message,
            @Header("kafka_receivedTopic") String topic,
            @Header("kafka_receivedPartitionId") String partition,
            @Header("kafka_receivedTimestamp") String timestamp
    ) {
        long startTime = System.currentTimeMillis();

        try {
            JsonNode jsonNode = objectMapper.readTree(message);

            String stockCode = jsonNode.get("stockCode").asText();
            String stockName = jsonNode.get("stockName").asText();
            String currentPrice = jsonNode.get("currentPrice").asText();
            String changePrice = jsonNode.get("changePrice").asText();
            String changeRate = jsonNode.get("changeRate").asText();
            String changeSign = jsonNode.get("changeSign").asText();

            // ë©”ëª¨ë¦¬ ìºì‹œì— ì €ì¥
            Map<String, Object> stockData = Map.of(
                "stockCode", stockCode,
                "stockName", stockName,
                "currentPrice", currentPrice,
                "changePrice", changePrice,
                "changeRate", changeRate,
                "changeSign", changeSign,
                "timestamp", LocalDateTime.now()
            );

            realTimeStockCache.put(stockCode, stockData);

            // ì²˜ë¦¬ëŸ‰ ì¦ê°€
            long processingTime = System.currentTimeMillis() - startTime;
            totalMessagesProcessed.incrementAndGet();
            totalProcessingTime.addAndGet(processingTime);

            log.debug("ğŸ“ˆ Kafka ìˆ˜ì‹  - ì‹¤ì‹œê°„ ë°ì´í„°: {} - {} (ì²˜ë¦¬ì‹œê°„: {}ms)",
                     stockCode, currentPrice, processingTime);

            // ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì „ì†¡ (10ê°œë§ˆë‹¤)
            if (totalMessagesProcessed.get() % 10 == 0) {
                sendPerformanceMetrics();
            }

        } catch (Exception e) {
            log.error("âŒ Kafka ë©”ì‹œì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {}", e.getMessage(), e);
        }
    }

    /**
     * ë°°ì¹˜ ë°ì´í„° ìˆ˜ì‹ 
     */
    @KafkaListener(topics = "stock-batch-data", groupId = "wts-consumer-group")
    public void consumeBatchStockData(
            @Payload String message,
            @Header("kafka_receivedTopic") String topic
    ) {
        long startTime = System.currentTimeMillis();

        try {
            JsonNode jsonNode = objectMapper.readTree(message);

            String batchId = jsonNode.get("batchId").asText();
            String type = jsonNode.get("type").asText();

            log.info("ğŸ“¦ Kafka ìˆ˜ì‹  - ë°°ì¹˜ ë°ì´í„°: {} (íƒ€ì…: {})", batchId, type);

            // ë°°ì¹˜ ë°ì´í„° ì²˜ë¦¬ ë¡œì§
            // ì‹¤ì œë¡œëŠ” ì—¬ê¸°ì— ë°°ì¹˜ ì²˜ë¦¬ ë¡œì§ì„ êµ¬í˜„

            long processingTime = System.currentTimeMillis() - startTime;
            log.debug("âœ… ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ: {} (ì²˜ë¦¬ì‹œê°„: {}ms)", batchId, processingTime);

        } catch (Exception e) {
            log.error("âŒ ë°°ì¹˜ ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨: {}", e.getMessage(), e);
        }
    }

    /**
     * ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì‹  (ë‹¤ë¥¸ ì„œë¹„ìŠ¤ì—ì„œ ë³´ë‚¸ ë©”íŠ¸ë¦­)
     */
    @KafkaListener(topics = PERFORMANCE_METRICS_TOPIC, groupId = "wts-consumer-group")
    public void consumePerformanceMetrics(
            @Payload String message,
            @Header("kafka_receivedTopic") String topic
    ) {
        try {
            JsonNode jsonNode = objectMapper.readTree(message);

            String metricType = jsonNode.get("metricType").asText();
            String service = jsonNode.get("service").asText();

            log.info("ğŸ“Š Kafka ìˆ˜ì‹  - ì„±ëŠ¥ ë©”íŠ¸ë¦­: {} from {}", metricType, service);

        } catch (Exception e) {
            log.error("âŒ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì²˜ë¦¬ ì‹¤íŒ¨: {}", e.getMessage(), e);
        }
    }

    /**
     * ì‹¤ì‹œê°„ ë°ì´í„° ì¡°íšŒ (WebSocket ëŒ€ì‹  Kafka ìºì‹œì—ì„œ)
     */
    public Map<String, Object> getRealTimeStockData(String stockCode) {
        return realTimeStockCache.get(stockCode);
    }

    /**
     * ëª¨ë“  ì‹¤ì‹œê°„ ë°ì´í„° ì¡°íšŒ
     */
    public Map<String, Map<String, Object>> getAllRealTimeStockData() {
        return new ConcurrentHashMap<>(realTimeStockCache);
    }

    /**
     * ìºì‹œëœ ì¢…ëª© ìˆ˜
     */
    public int getCachedStockCount() {
        return realTimeStockCache.size();
    }

    /**
     * ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì „ì†¡
     */
    private void sendPerformanceMetrics() {
        try {
            long avgProcessingTime = totalMessagesProcessed.get() > 0
                ? totalProcessingTime.get() / totalMessagesProcessed.get()
                : 0;

            kafkaStockService.sendWTSPerformanceMetrics(
                activeConnections.get(),
                realTimeStockCache.size(),
                avgProcessingTime,
                0.0, // CPU ì‚¬ìš©ëŸ‰ (ì‹œìŠ¤í…œì—ì„œ ê°€ì ¸ì™€ì•¼ í•¨)
                Runtime.getRuntime().totalMemory() - Runtime.getRuntime().freeMemory()
            );

        } catch (Exception e) {
            log.error("âŒ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì „ì†¡ ì‹¤íŒ¨: {}", e.getMessage(), e);
        }
    }

    /**
     * ì—°ê²° ìˆ˜ ì¦ê°€
     */
    public void incrementActiveConnections() {
        activeConnections.incrementAndGet();
    }

    /**
     * ì—°ê²° ìˆ˜ ê°ì†Œ
     */
    public void decrementActiveConnections() {
        activeConnections.decrementAndGet();
    }

    /**
     * í˜„ì¬ ìƒíƒœ ì¡°íšŒ
     */
    public Map<String, Object> getConsumerStatus() {
        long avgProcessingTime = totalMessagesProcessed.get() > 0
            ? totalProcessingTime.get() / totalMessagesProcessed.get()
            : 0;

        return Map.of(
            "totalMessagesProcessed", totalMessagesProcessed.get(),
            "avgProcessingTime", avgProcessingTime,
            "cachedStocks", realTimeStockCache.size(),
            "activeConnections", activeConnections.get(),
            "timestamp", LocalDateTime.now()
        );
    }
}
