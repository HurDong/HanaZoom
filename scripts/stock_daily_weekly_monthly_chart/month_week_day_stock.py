# pip install pykrx pandas tqdm tenacity
from pykrx import stock
import pandas as pd
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
from tenacity import retry, wait_exponential, stop_after_attempt
from time import sleep
import os
from tqdm import tqdm
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('stock_data_collection.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

CODES = [
    "005930","000660","207940","373220","105560","051910","006400","033780","003550","012330",
    "017670","090430","009830","012450","010140","088350","034020","003490","028260","066570",
    "009150","096770","024110","316140","011200","010130","055550","030200","011170","004990",
    "336260","029780","000120","000720","086280","002380","004020","011790","006360","036570",
    "035250","402340","018260","023530","008770","069960","035760","139480","010950","456040",
    "375500","064350","018880","007070","120110","011210","000880","006650","001450","180640",
    "004000","282330","112610","009240","047040","161390","089860","008930","251270","032830",
    "028670","051900","016360","071050","047810","035720","086790","005940","078930","097950",
    "036460","005830","034730","128940","035420","011780","069500","005380","005490","015760",
    "204320","000150","010120","010620","009540","000810","326030"
]

START = "20100101"
END   = datetime.now().strftime("%Y%m%d")
OUT   = "./out_krx_parallel"

os.makedirs(OUT, exist_ok=True)

def normalize(df: pd.DataFrame) -> pd.DataFrame:
    m = {"ì‹œê°€":"open","ê³ ê°€":"high","ì €ê°€":"low","ì¢…ê°€":"close","ê±°ë˜ëŸ‰":"volume"}
    df = df.rename(columns=m).sort_index()
    keep = [c for c in ["open","high","low","close","volume"] if c in df.columns]
    return df[keep].astype("float64")

def to_weekly(df_daily: pd.DataFrame) -> pd.DataFrame:
    return (df_daily
            .resample("W-FRI")
            .agg({"open":"first","high":"max","low":"min","close":"last","volume":"sum"})
            .dropna())

@retry(wait=wait_exponential(multiplier=0.5, min=0.5, max=8), stop=stop_after_attempt(5))
def fetch_one(code: str):
    try:
        logger.info(f"ğŸ“Š {code} ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
        
        # ì¼ë³„ ë°ì´í„°
        logger.info(f"  â””â”€ {code} ì¼ë³„ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
        day = stock.get_market_ohlcv_by_date(START, END, code, freq="d")
        logger.info(f"  â””â”€ {code} ì¼ë³„ ë°ì´í„° ì™„ë£Œ ({len(day)}ê°œ í–‰)")
        
        # ì›”ë³„ ë°ì´í„°
        logger.info(f"  â””â”€ {code} ì›”ë³„ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
        mon = stock.get_market_ohlcv_by_date(START, END, code, freq="m")
        logger.info(f"  â””â”€ {code} ì›”ë³„ ë°ì´í„° ì™„ë£Œ ({len(mon)}ê°œ í–‰)")
        
        # ë°ì´í„° ì •ê·œí™”
        day, mon = normalize(day), normalize(mon)
        wk = to_weekly(day)
        logger.info(f"  â””â”€ {code} ì£¼ë³„ ë°ì´í„° ìƒì„± ì™„ë£Œ ({len(wk)}ê°œ í–‰)")
        
        logger.info(f"âœ… {code} ëª¨ë“  ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")
        return code, day, wk, mon
        
    except Exception as e:
        logger.error(f"âŒ {code} ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
        raise

def save(code, day, wk, mon):
    try:
        for frame, suf in [(day,"D"), (wk,"W"), (mon,"M")]:
            p = f"{OUT}/{code}_{suf}.csv"
            frame.index.name = "date"
            frame.to_csv(p, encoding="utf-8")
        logger.info(f"ğŸ’¾ {code} íŒŒì¼ ì €ì¥ ì™„ë£Œ")
    except Exception as e:
        logger.error(f"âŒ {code} íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
        raise

def main():
    logger.info("ğŸš€ ì£¼ì‹ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘!")
    logger.info(f"ğŸ“… ê¸°ê°„: {START} ~ {END}")
    logger.info(f"ğŸ“ ì¶œë ¥ í´ë”: {OUT}")
    logger.info(f"ğŸ“ˆ ëŒ€ìƒ ì¢…ëª© ìˆ˜: {len(CODES)}ê°œ")
    
    # ë™ì‹œì„±: 6~10 ì‚¬ì´ ì¶”ì²œ (ê³¼ë„í•œ ë™ì‹œì„±ì€ ì°¨ë‹¨/ì˜¤ë¥˜â†‘). KIS/API ì‚¬ìš© ì‹œì—” API ì œí•œì— ë§ì¶° ë” ë‚®ê²Œ.
    MAX_WORKERS = 8
    logger.info(f"ğŸ”§ ë™ì‹œ ì²˜ë¦¬ ì›Œì»¤ ìˆ˜: {MAX_WORKERS}")
    
    completed_count = 0
    error_count = 0
    
    # ì§„í–‰ë¥  ë°” ìƒì„±
    pbar = tqdm(total=len(CODES), desc="ğŸ“Š ì£¼ì‹ ë°ì´í„° ìˆ˜ì§‘", unit="ì¢…ëª©")
    
    futures = []
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:
        # ì‘ì—… ì œì¶œ
        for code in CODES:
            futures.append(ex.submit(fetch_one, code))
            sleep(0.05)  # ë¯¸ì„¸í•œ ê°„ê²© ë‘ê¸°(ì„œë²„ ë¶€ë‹´/ìŠ¤íŒŒì´í¬ ì™„í™”)
        
        logger.info("ğŸ“¤ ëª¨ë“  ì‘ì—… ì œì¶œ ì™„ë£Œ, ê²°ê³¼ ì²˜ë¦¬ ì‹œì‘...")
        
        # ê²°ê³¼ ì²˜ë¦¬
        for fut in as_completed(futures):
            try:
                code, day, wk, mon = fut.result()
                save(code, day, wk, mon)
                completed_count += 1
                logger.info(f"ğŸ¯ {code} ì™„ë£Œ ({completed_count}/{len(CODES)})")
                
            except Exception as e:
                error_count += 1
                logger.error(f"ğŸ’¥ {code} ì‹¤íŒ¨: {str(e)}")
            
            pbar.update(1)
            pbar.set_postfix({
                'ì™„ë£Œ': f'{completed_count}/{len(CODES)}',
                'ì‹¤íŒ¨': error_count,
                'ì§„í–‰ë¥ ': f'{((completed_count + error_count) / len(CODES) * 100):.1f}%'
            })
    
    pbar.close()
    
    # ìµœì¢… ê²°ê³¼ ìš”ì•½
    logger.info("=" * 50)
    logger.info("ğŸ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")
    logger.info(f"âœ… ì„±ê³µ: {completed_count}ê°œ")
    logger.info(f"âŒ ì‹¤íŒ¨: {error_count}ê°œ")
    logger.info(f"ğŸ“Š ì´ ì§„í–‰ë¥ : {(completed_count / len(CODES) * 100):.1f}%")
    logger.info(f"ğŸ“ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {os.path.abspath(OUT)}")
    logger.info("=" * 50)

if __name__ == "__main__":
    main()
